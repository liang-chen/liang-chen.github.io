<!doctype html>
<html>
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
<style>
body {
  font-family: Helvetica, arial, sans-serif;
  font-size: 14px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

body > *:first-child {
  margin-top: 0 !important; }
body > *:last-child {
  margin-bottom: 0 !important; }

a {
  color: #4183C4; }
a.absent {
  color: #cc0000; }
a.anchor {
  display: block;
  padding-left: 30px;
  margin-left: -30px;
  cursor: pointer;
  position: absolute;
  top: 0;
  left: 0;
  bottom: 0; }

h1, h2, h3, h4, h5, h6 {
  margin: 20px 0 10px;
  padding: 0;
  font-weight: bold;
  -webkit-font-smoothing: antialiased;
  cursor: text;
  position: relative; }

h1:hover a.anchor, h2:hover a.anchor, h3:hover a.anchor, h4:hover a.anchor, h5:hover a.anchor, h6:hover a.anchor {
  background: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAA09pVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMy1jMDExIDY2LjE0NTY2MSwgMjAxMi8wMi8wNi0xNDo1NjoyNyAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNiAoMTMuMCAyMDEyMDMwNS5tLjQxNSAyMDEyLzAzLzA1OjIxOjAwOjAwKSAgKE1hY2ludG9zaCkiIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OUM2NjlDQjI4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OUM2NjlDQjM4ODBGMTFFMTg1ODlEODNERDJBRjUwQTQiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo5QzY2OUNCMDg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo5QzY2OUNCMTg4MEYxMUUxODU4OUQ4M0REMkFGNTBBNCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PsQhXeAAAABfSURBVHjaYvz//z8DJYCRUgMYQAbAMBQIAvEqkBQWXI6sHqwHiwG70TTBxGaiWwjCTGgOUgJiF1J8wMRAIUA34B4Q76HUBelAfJYSA0CuMIEaRP8wGIkGMA54bgQIMACAmkXJi0hKJQAAAABJRU5ErkJggg==) no-repeat 10px center;
  text-decoration: none; }

h1 tt, h1 code {
  font-size: inherit; }

h2 tt, h2 code {
  font-size: inherit; }

h3 tt, h3 code {
  font-size: inherit; }

h4 tt, h4 code {
  font-size: inherit; }

h5 tt, h5 code {
  font-size: inherit; }

h6 tt, h6 code {
  font-size: inherit; }

h1 {
  font-size: 28px;
  color: black; }

h2 {
  font-size: 24px;
  border-bottom: 1px solid #cccccc;
  color: black; }

h3 {
  font-size: 18px; }

h4 {
  font-size: 16px; }

h5 {
  font-size: 14px; }

h6 {
  color: #777777;
  font-size: 14px; }

p, blockquote, ul, ol, dl, li, table, pre {
  margin: 15px 0; }

hr {
  background: transparent url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x 0 0;
  border: 0 none;
  color: #cccccc;
  height: 4px;
  padding: 0;
}

body > h2:first-child {
  margin-top: 0;
  padding-top: 0; }
body > h1:first-child {
  margin-top: 0;
  padding-top: 0; }
  body > h1:first-child + h2 {
    margin-top: 0;
    padding-top: 0; }
body > h3:first-child, body > h4:first-child, body > h5:first-child, body > h6:first-child {
  margin-top: 0;
  padding-top: 0; }

a:first-child h1, a:first-child h2, a:first-child h3, a:first-child h4, a:first-child h5, a:first-child h6 {
  margin-top: 0;
  padding-top: 0; }

h1 p, h2 p, h3 p, h4 p, h5 p, h6 p {
  margin-top: 0; }

li p.first {
  display: inline-block; }
li {
  margin: 0; }
ul, ol {
  padding-left: 30px; }

ul :first-child, ol :first-child {
  margin-top: 0; }

dl {
  padding: 0; }
  dl dt {
    font-size: 14px;
    font-weight: bold;
    font-style: italic;
    padding: 0;
    margin: 15px 0 5px; }
    dl dt:first-child {
      padding: 0; }
    dl dt > :first-child {
      margin-top: 0; }
    dl dt > :last-child {
      margin-bottom: 0; }
  dl dd {
    margin: 0 0 15px;
    padding: 0 15px; }
    dl dd > :first-child {
      margin-top: 0; }
    dl dd > :last-child {
      margin-bottom: 0; }

blockquote {
  border-left: 4px solid #dddddd;
  padding: 0 15px;
  color: #777777; }
  blockquote > :first-child {
    margin-top: 0; }
  blockquote > :last-child {
    margin-bottom: 0; }

table {
  padding: 0;border-collapse: collapse; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }

img {
  max-width: 100%; }

span.frame {
  display: block;
  overflow: hidden; }
  span.frame > span {
    border: 1px solid #dddddd;
    display: block;
    float: left;
    overflow: hidden;
    margin: 13px 0 0;
    padding: 7px;
    width: auto; }
  span.frame span img {
    display: block;
    float: left; }
  span.frame span span {
    clear: both;
    color: #333333;
    display: block;
    padding: 5px 0 0; }
span.align-center {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-center > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: center; }
  span.align-center span img {
    margin: 0 auto;
    text-align: center; }
span.align-right {
  display: block;
  overflow: hidden;
  clear: both; }
  span.align-right > span {
    display: block;
    overflow: hidden;
    margin: 13px 0 0;
    text-align: right; }
  span.align-right span img {
    margin: 0;
    text-align: right; }
span.float-left {
  display: block;
  margin-right: 13px;
  overflow: hidden;
  float: left; }
  span.float-left span {
    margin: 13px 0 0; }
span.float-right {
  display: block;
  margin-left: 13px;
  overflow: hidden;
  float: right; }
  span.float-right > span {
    display: block;
    overflow: hidden;
    margin: 13px auto 0;
    text-align: right; }

code, tt {
  margin: 0 2px;
  padding: 0 5px;
  white-space: nowrap;
  border: 1px solid #eaeaea;
  background-color: #f8f8f8;
  border-radius: 3px; }

pre code {
  margin: 0;
  padding: 0;
  white-space: pre;
  border: none;
  background: transparent; }

.highlight pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }

pre {
  background-color: #f8f8f8;
  border: 1px solid #cccccc;
  font-size: 13px;
  line-height: 19px;
  overflow: auto;
  padding: 6px 10px;
  border-radius: 3px; }
  pre code, pre tt {
    background-color: transparent;
    border: none; }

sup {
    font-size: 0.83em;
    vertical-align: super;
    line-height: 0;
}
* {
	-webkit-print-color-adjust: exact;
}
@media screen and (min-width: 914px) {
    body {
        width: 854px;
        margin:0 auto;
    }
}
@media print {
	table, pre {
		page-break-inside: avoid;
	}
	pre {
		word-wrap: break-word;
	}
}
</style>
<title>Music Informatics Reading Group Bibliography</title>

</head>
<body>
<h1>Music Informatics Reading Group Bibliography</h1>

<ol>
<li><p>Optical Music Recognition</p>

<p> <em>Jan 23, 2015</em></p>

<ul>
<li><p><a href="http://homes.soic.indiana.edu/donbyrd/OMRTestbed/OMRStandardTestbed1Mar2013.pdf">Towards a Standard Testbed for Optical Music Recognition: Definitions, Metrics, and Page Images</a></p></li>
<li><p>Optical Music Imaging: Music Document Digitisation, Recognition, Evaluation, and Restoration</p></li>
<li><p><a href="http://ismir2007.ismir.net/proceedings/ISMIR2007_p123_knopke.pdf">TOWARDS MUSICDIFF: A FOUNDATION FOR IMPROVED OPTICAL
MUSIC RECOGNITION USING MULTIPLE RECOGNIZERS</a></p></li>
<li><p><a href="http://www.inescporto.pt/~jsc/publications/journals/2009JaimeTPAMI.pdf">Staff detection with Stable Paths</a></p></li>
<li><a href="http://ismir2011.ismir.net/papers/PS3-10.pdf">OCR-BASED POST-PROCESSING OF OMR FOR THE RECOVERY OF TRANSPOSING INSTRUMENTS IN COMPLEX ORCHESTRAL SCORES</a></li>
</ul>
</li>
<li><p>Expressive performance</p>

<p> <em>Jan 30, 2015</em></p>

<ul>
<li><p><a href="http://www.tandfonline.com/doi/pdf/10.1076/jnmr.30.1.39.7119">Automatic Extraction of Tempo and Beat From Expressive Performances        <br/>
</a></p></li>
<li><p><a href="http://www.eecs.qmul.ac.uk/~andrewr/papers/DannenbergSMC13.pdf">Human-Computer Music Performance: From Synchronized Accompaniment to Musical Partner
</a></p></li>
<li><p><a href="http://recherche.ircam.fr/equipes/repmus/SMC04/scm04actes/P32.pdf">STRATEGIES FOR CONTINUOUS PITCH AND AMPLITUDE TRACKING IN REAL TIME INTERACTIVE IMPROVISATION SOFTWARE</a></p></li>
<li><p><a href="http://ismir2009.ismir.net/proceedings/PS1-3.pdf">TOWARDS AUTOMATED EXTRACTION OF TEMPO PARAMETERS FROM EXPRESSIVE MUSIC RECORDINGS</a></p></li>
<li><p><a href="http://www.ofai.at/~werner.goebl/papers/Widmer-Goebl_JNMR2004.pdf">Computational Models of Expressive Music Performance: The State of the Art</a></p></li>
</ul>
</li>
<li><p>Automatic Transcription</p>

<p> <em>Feb 6, 2015</em></p>

<ul>
<li><p><a href="http://www.cs.tut.fi/sgn/arg/klap/jnmr_klapuri.pdf">Automatic music transcription as we know it today</a></p></li>
<li><p><a href="http://ismir2007.ismir.net/proceedings/ISMIR2007_p245_lee.pdf">A UNIFIED SYSTEM FOR CHORD TRANSCRIPTION AND KEY EXTRACTION USING HIDDEN MARKOV MODELS</a></p></li>
<li><p><a href="http://papers.nips.cc/paper/5432-unsupervised-transcription-of-piano-music.pdf">Unsupervised Transcription of Piano Music</a></p></li>
<li><p><a href="http://www.eecs.qmul.ac.uk/~simond/pub/2011/Benetos-Dixon-SMC2011.pdf">MULTIPLE-INSTRUMENT POLYPHONIC MUSIC TRANSCRIPTION USING A CONVOLUTIVE PROBABILISTIC MODEL</a></p></li>
<li><p><a href="https://www.ee.columbia.edu/~dpwe/pubs/GrindE11-eigeninst.pdf">Transcribing Multi-instrument Polyphonic Music
with Hierarchical Eigeninstruments</a></p></li>
</ul>
</li>
<li><p>Music Structure Analysis</p>

<p> <em>Feb 11, 2015</em></p>

<ul>
<li><p><a href="http://make.cs.nthu.edu.tw/makeWeb/alp/alp_paper/Discovering%20non-trivial%20repeating%20patterns%20in%20music%20data.pdf">Discovering Nontrivial Repeating Patterns in Music Data</a></p></li>
<li><p><a href="https://ccrma.stanford.edu/~craig/papers/05/sapp-ismir2005A4.pdf">Online Database of Scores in the Humdrum File Format</a></p>

<ul>
<li>Check out result at:
<a href="http://kern.humdrum.org/help/tour/">Kern Scores</a></li>
</ul>
</li>
<li><p><a href="http://extras.humdrum.org/man/mkeyscape/">HumDrum Extras</a></p></li>
<li><p><a href="http://207.21.18.5/publications/summarizing-popular-music-via-structural-similarity-analysis.pdf">Summarizing Popular Music Via Structural Similarity Analysis</a></p></li>
<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.71.9243&amp;rep=rep1&amp;type=pdf">Structural Analysis of Musical Signals for Indexing and Thumbnailing</a></p></li>
</ul>
</li>


<li><p>Music Emotion Recognition</p>
<p> <em>Feb 20, 2015</em></p>
<ul>
<li><p><a href="http://www.ismir2011.ismir.net/papers/OS9-1.pdf">MODELING MUSICAL EMOTION DYNAMICS WITH CONDITIONAL RANDOM FIELDS</a></p></li>
<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.331.1655&rep=rep1&type=pdf">A Regression Approach to Music Emotion Recognition</a></p></li>
<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.231.7740&rep=rep1&type=pdf">Music emotion recognition: a state of the art review</a></p></li>
<li><p><a href="http://ismir2012.ismir.net/event/papers/265_ISMIR_2012.pdf">AN EMOTION MODEL FOR MUSIC USING BRAIN WAVES</a></p></li>
<li><p><a href="http://music.ece.drexel.edu/research/emotion">Music Emotion Recognition Projects</a></p></li>
</ul>
</li>

<li><p>Music Recommendation System</p>
<p> <em>Feb 27, 2015</em></p>
<ul>
<li><p><a href="http://papers.nips.cc/paper/3370-automatic-generation-of-social-tags-for-music-recommendation.pdf">Automatic Generation of Social Tags for Music Recommendation</a></p></li>
<li><p><a href="http://130.54.20.150/members/yoshii/papers/ismir-2006-yoshii.pdf">Hybrid Collaborative and Content-based Music Recommendation Using Probabilistic Model with Latent User Preferences</a></p></li>
<li><p><a href="http://papers.nips.cc/paper/5004-deep-content-based-music-recommendation.pdf">Deep content-based music recommendation</a></p></li>
<li><p><a href="http://ismir2005.ismir.net/proceedings/2072.pdf">DYNAMIC PLAYLIST GENERATION BASED ON SKIPPING BEHAVIOR</a></p></li>
</ul>
</li>


<li><p>Rhythm and Beat</p>
<p> <em>Mar 6, 2015</em></p>
<ul>
<li><p><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.1.4218&rep=rep1&type=pdf">Analysis of the Meter of Acoustic Musical Signals</a></p></li>
<li><p><a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T116_357_Paper.pdf">Improving rhythmic transcriptions via probability models applied post-omr</a></p></li>
<li><p><a href="http://phenicx.upf.edu/system/files/publications/Krebs_ISMIR_2013.pdf">RHYTHMIC PATTERN MODELING FOR BEAT AND DOWNBEAT TRACKING IN MUSICAL AUDIO</a></p></li>
<li><p><a href="https://www.fxpal.com/publications/the-beat-spectrum-a-new-approach-to-rhythm-analysis.pdf">The beat spectrum: a new approach to rhythm analysis</a></p></li>
</ul>
</li>

<li><p>Sound Quality</p>
<p> <em>Mar 13, 2015</em></p>
<ul>
<li><p><a href="https://aaltodoc.aalto.fi/handle/123456789/14206">Equalization Techniques for Headphone Listening</a></p></li>
<li><p><a href="https://aaltodoc.aalto.fi/bitstream/handle/123456789/14206/article1.pdf?sequence=12">Signal Processing Framework for Virtual Headphone Listening Test in a Noisy Environment</a></p></li>
<li><p><a href="https://mediatech.aalto.fi/~jpatynen/papers/patynen2008anechoic.pdf">Anechoic Recording System for Symphony Orchestra</a></p></li>
<li><p><a href="http://www.alejandrocasales.com/teoria/teoria/Markov_Model.pdf">Audio Imputation Using the Non-negative Hidden Markov Model</a></p></li>
</ul>
</li>

<li><p>Automatic Accompaniment</p>
<p> <em>Mar 27, 2015</em></p>
<ul>
<li><p><a href="http://research.microsoft.com/en-us/um/people/dan/mysong/MySongCHI2008.pdf">MySong: automatic accompaniment generation for vocal melodies</a></p></li>
<li><p><a href="http://www.jstor.org/stable/pdf/1391101.pdf">A probabilistic Expert System for Automatic Music Accompaniment</a></p></li>
<li><p><a href="http://eplex.cs.ucf.edu/papers/hoover_smc11.pdf">A hybrid system for automatic generation of style-specific accompaniment</a></p></li>
<li><p><a href="http://riuma.uma.es/xmlui/bitstream/handle/10630/5685/SMC2013_Proceedings">Virtual conductor for string quartet practice</a></p></li>
<li><p><a href="http://delivery.acm.org/10.1145/1300000/1291424/p839-li.pdf?ip=149.160.136.191&id=1291424&acc=ACTIVE%20SERVICE&key=EA62C54EFA59E1BA%2EEC3C9CD27046E2ED%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&CFID=493097337&CFTOKEN=74775385&__acm__=1427556422_feb1425784d297dc8ca121c02eab07d9">Emotion-based impressionism slideshow with automatic music accompaniment</a></p></li>
</ul>
</li>

<li><p>Random Topics</p>
<p> <em>April 3, 2015</em></p>
<ul>
<li><p><a href="https://hal.inria.fr/hal-01116686v2/document">Kernel additive modeling for interference reduction in multi-channel music recordings</a></p></li>
<li><p><a href="http://www.terasoft.com.tw/conf/ismir2014/proceedings/T089_194_Paper.pdf">TOWARDS SEAMLESS NETWORK MUSIC PERFORMANCE: PREDICTING AN ENSEMBLEâ€™S EXPRESSIVE DECISIONS FOR DISTRIBUTED PERFORMANCE</a></p></li>
<li><p><a href="http://ismir2007.ismir.net/proceedings/ISMIR2007_p261_kurth.pdf">AUTOMATED SYNCHRONIZATION OF SCANNED SHEET MUSIC WITH AUDIO RECORDINGS</a></p></li>
</ul>
</li>

<li><p>Random Topics</p>
<p> <em>April 10, 2015</em></p>
<ul>
<li><p><a href="http://www.isip.piconepress.com/courses/temple/ece_8527/lectures/2014_spring/lecture_38_spmag.pdf">Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups</a></p></li>
<li><p><a href="http://www.ece.rochester.edu/~zduan/teaching/ece477/projects/2014/Mingfeng_Zhang_ReportFinal.pdf">Parametric Analysis of Musical Vibrato in Voice and Instrument Performance </a> (Course Project of <a href="http://www.ece.rochester.edu/~zduan/teaching/ece477/index.html">Audio Signal Processing</a>)</p></li>
<li><p><a href="http://ismir2011.ismir.net/papers/OS1-3.pdf">A SYSTEM FOR EVALUATING SINGING ENTHUSIASM FOR KARAOKE</a></p></li>
<li><p><a href="http://people.csail.mit.edu/mrub/VisualMic/">The visual microphone: Passive Recovery of Sound from Video</a></p></li>
</ul>
</li>


</ol>

</body>
</html>
